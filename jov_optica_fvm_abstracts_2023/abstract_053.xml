<?xml version="1.0"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN" "http://jats.nlm.nih.gov/publishing/1.0/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="Optica Fall Vision Meeting Abstract">
	<front>
		<journal-meta>
			<journal-id journal-id-type="hwp">jov</journal-id>
			<journal-id journal-id-type="publisher-id">JOVI</journal-id>
			<journal-title-group>
				<journal-title>Journal of Vision</journal-title>
			</journal-title-group>
			<issn pub-type="epub">1534-7362</issn>
			<publisher>
				<publisher-name>Association for Research in Vision and Ophthalmology</publisher-name>
			</publisher>
		</journal-meta>
		<article-meta>
			<article-id pub-id-type="doi">10.1167/jov.23.13.53</article-id>
			<article-id pub-id-type="manuscript">Talks_53</article-id>
			<article-categories>
				<subj-group subj-group-type="category">
					<subject>Poster Session I</subject>
				</subj-group>
			</article-categories>
			<title-group>
				<article-title>Poster Session I: Leveraging AI to accelerate scientific discoveries</article-title>
			</title-group>
			<contrib-group>
                          
				<contrib contrib-type="author">
					<name>
						<surname>Oruc</surname>
						<given-names>Ipek</given-names>
					</name>
                                        
					<xref ref-type="aff" rid="aff1"><sup>1</sup></xref>


				</contrib>



				<contrib contrib-type="author">
					<name>
						<surname>Delavari</surname>
						<given-names>Parsa</given-names>
					</name>
                                        
					<xref ref-type="aff" rid="aff1"><sup>1</sup></xref>


				</contrib>



				<contrib contrib-type="author">
					<name>
						<surname>Ozturan</surname>
						<given-names>Gulcenur</given-names>
					</name>
                                        
					<xref ref-type="aff" rid="aff1"><sup>1</sup></xref>


				</contrib>



				<contrib contrib-type="author">
					<name>
						<surname>Yuan</surname>
						<given-names>Lei</given-names>
					</name>
                                        
					<xref ref-type="aff" rid="aff1"><sup>1</sup></xref>


				</contrib>



				<contrib contrib-type="author">
					<name>
						<surname>Yilmaz</surname>
						<given-names>Ozgur</given-names>
					</name>
                                        
					<xref ref-type="aff" rid="aff1"><sup>1</sup></xref>


				</contrib>




                          
				<aff id="aff1">
					<label><sup>1</sup></label>
					<institution>University of British Columbia</institution>
				</aff>


			</contrib-group>
			<pub-date pub-type="ppub"><month>11</month>
				<year>2023</year>
			</pub-date>
			<pub-date pub-type="epub"><month>11</month>
				<year>2023</year>
			</pub-date>
						<volume>23</volume>
						<issue>13</issue>
						<fpage>53</fpage>
						<lpage>53</lpage>
			<permissions>
				<license license-type="cc-by-nc-nd" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">
					<license-p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.</license-p>
				</license>
			</permissions>
			<abstract>
				<p>We introduce a structured approach that leverages AI to accelerate scientific discoveries. We showcase the efficacy of this technique via a proof-of-concept study identifying markers of sex in retinal images. Our methodology consists of four stages: In Phase 1, CNN development, we train a VGG model to recognize patient sex from retinal images. Phase 2, Inspiration, involves reviewing post-hoc interpretation tools&#39; visualizations to draw observations and formulate exploratory hypotheses regarding the CNN model&#39;s decision process. This yielded 14 testable hypotheses related to potential variances in vasculature and optic disc. In Phase 3, Exploration, we test these hypotheses on an independent dataset, of which nine demonstrated significant differences. In Phase 4, Verification, five out of nine these nine hypotheses are re-tested on a new dataset, verifying five of them: significantly greater length, more nodes and branches of retinal vasculature, a larger area covered by vessels in the superior temporal quadrant, and a darker peri-papillary region in male eyes. Finally, we conducted a psychophysical study and trained a group of ophthalmologists (N=26) to identify these new retinal features for sex classification. Their performance, initially on par with chance and a non-expert group (N=31), significantly improved post-training (p&lt;.001, d=2.63). These outcomes illustrate the potential of our methodology in leveraging AI applications for retinal biomarker discovery.</p>
			</abstract>
		</article-meta>
	</front>
	<back>
                
               <fn-group>
			<fn>
				<p>Funding: Funding: NSERC Discovery, NSERC Accelerator.</p>
			</fn>
		</fn-group>

	</back>
</article>